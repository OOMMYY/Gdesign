<center><h1>基于LWF的人脸识别系统</h1></center>

#####计算性能没有写、tensorflow 可以再补充一些，PCA算法需要补充。


##摘要
&#160; &#160; &#160; &#160;人脸识别作为人工智能的一个重要领域，很多科学家都把攻克这领域作为人生目标，我国从上世界九十年代就开始了人工智能领域的探索，国家在这方面投入了巨大的人力与财力，同时也取得了非常大的成就。2005年，国家“十五”攻关项目《人脸识别系统》通过专家鉴定，人脸识别可疑应用于公安领域的反恐与追查逃犯，2013年我国使用人脸识别进行户籍查重，一共查出了79万的重复户口。人脸识别一方面获得了政府的大力支持，另一方面广大民营企业也在加大研发力度，阿里巴巴的董事长马云在德国汉诺威国际信息及通信技术博览会开幕式上就向全世界推广自己的刷脸购物技术。<br>
&#160; &#160; &#160; &#160;人脸识别主要分为四部分：人脸检测、人脸校准、人脸认证、人脸识别。人脸经过数据采集设备生成人脸图像信息，图片可以是立体图片或者彩色图片或者黑白图片；获取图片后，我们需要把人脸从图片信息中提取出来，经过这一步操作我们可以把图片中的其他无关信息给过滤掉，人脸信息经过处理之后会给它分配一个标签，这样人脸信息就与人的身份形成一个映射关系。最后一步是我们把没有标签的人脸照片打上标签的过程，这个过程又分人脸验证与人脸识别，人脸验证是指比较两张图片是不是同一个人，人脸识别是指给定一个人脸然后从数据库中找出它属于哪个人，前者是后者的基础，后者更为复杂。人脸验证的算法最经典的就是PCA算法，PCA算法虽然现在已经不适用于现实系统中但是很多的算法也会把PCA做为一个中间步骤。人工神经网络与深度学习是人脸识别的一个新方向，目前人脸识别领域做得最好的算法是多层卷积神经网络。<br>

关键词：
<br>&#160; &#160; &#160; &#160;人脸识别, LWF, PCA, Django, SVM, Keras, 卷积神经网络，OpenCV, scikit-learn##Abstract
&#160; &#160; &#160; &#160;Face recognition is an important field of artificial intelligence, many scientists have captured the hill as a personal goal, China from 90s began to explore the world of artificial intelligence, the state has invested enormous financial and human resources in this area, but also has made great achievements. In 2005, the national "fifteen" project "face recognition system" by experts, face recognition is applied to the field of public security against terrorism suspect and trace the fugitive, in 2013 China's face recognition using household investigation, a total of 790 thousand duplicate accounts found. Face recognition has gained the support of the government, on the other hand, the majority of private enterprises are also increasing R & D efforts, Alibaba chairman Ma Yun in Germany Hannover international information and communication technology, the opening ceremony of the Expo to the world to promote their own shopping technology face brush.<br>
&#160; &#160; &#160; &#160;Face recognition is mainly divided into four parts: face detection, face calibration, face authentication and face recognition. Face through the data acquisition device generates a face image information, the picture can be stereo images or color images or black-and-white pictures; get the picture, we need to face is extracted from the image information, after this step we can put other irrelevant information in the image to filter out, face information after treatment will assign a label to it, such as the identity of the face information and form a mapping relationship. The last step is the process we face photos without labels tagged, this process also face verification and face recognition, face verification refers to the comparison of the two picture is not the same person, face recognition is given a face and then from the database to find it belongs to one, the former is the foundation of the latter the latter is more complex. Face verification algorithm is the most classic PCA algorithm, PCA algorithm is now not applicable to the actual system, but many algorithms will also PCA as an intermediate step. Artificial neural network and depth learning is a new direction of face recognition. The best algorithm in the field of face recognition is multilayer convolutional neural network.

Key word：
<br>&#160; &#160; &#160; &#160;
Face recognition, LWF, PCA, Django, SVM, Keras, convolutional neural network，OpenCV, scikit-learn

##目录
1.绪论

1.1 背景与意义

1.2 人脸识别的历史

1.3 论文结构

2.技术路线

2.1 Scikit-learn与LWF

2.2 Keras卷积神经网络

3.技术介绍

3.1 Django

3.1.1 Django url 转发

3.1.2 Django 访问静态资源

3.1.3 Django 获取request资源

3.2 Scikit-learn

3.2.1 监督学习

3.2.2 无监督学习

3.3.3 模型选择与评估

3.3.4 计算性能

3.3 Tensorflow

3.4 Keras

3.5 OpenCV

4.算法介绍

4.1 PCA算法

4.2 SVM

4.3 卷积神经网络

5.实验数据

5.1 Scikit-learn实验数据

5.2 Keras实验数据

6.平台展示

6.1 认证、验证平台界面

7.程序测试

7.1 程序测试

8.结论

9.致谢

10.参考文献
##1.绪论
###1.1 背景与意义

&#160; &#160; &#160; &#160;人脸识别是模式识别和计算机视觉的重要课题之一，科学家们对与人脸识别领域的探索必将敲开人工智能的大门。现代我们的社会发展地越来越快了，人类已经经历过第一次工业革命、第二次工业革命，现在正在经历着第三次工业革命。第一次工业革命发展的是蒸汽机，那个时代的蒸汽机把人来从沉重的体力劳动中解放出来，第二次工业革命人类社会步入电气时代，电力进一步解放劳动力，同时电气行业的发展也给了工程师施展才华的地方，工程师可以根据规则创造一些自动化的工具来帮助人们进行生产活动，第二次工业革命也创造出了一种能源货币——电力。几乎所有的能源都能够转化成电能，电能也可以通过做功的方式转化为所有其他的能量。现在我们正在经历的是第三次工业革命——信息革命，信息革命以互联网的兴起为标志，互联网以让人们更加方便快捷的方式获取信息为使命，可以影响到各行各业。在信息革命中工程师不断地探索，创造出了社交软件与搜索引擎，一下子让人类拥有了千里眼、顺风耳和无所不知的能力。信息革命向前更近一步就到达了人工智能的领地，人工智能就像一个神，它无所不知，它拥有无穷的智慧。<br>
&#160; &#160; &#160; &#160;人脸识别时人工智能的重要应用场景之一。人脸识别现在已经开始应用与考勤打卡、公司门禁系统、追捕罪犯、金融行业身份认证…… 在未来的二十年中人脸识别技术会更加广泛地应用于我们社会的各行各业。以人脸识别技术为代表的生物信息身份认证技术会让各行各业的身份认证验证环节变得更加高效：到时候具备人脸识别功能的机器人就会接替一系列的与识别人脸相关的工作岗位，其中最具代表性的就是单位或公司门口的门卫，机场或火车站的车票核验人员，各类办证窗口的办事人员。人脸识别所用到的特征提取与分类技术是人工智能的通用技术，这些技术稍加改造就能应用于人工智能领域的其它应用场景。比如说语音识别、无人驾驶、机器问答、机器写作和机器翻译。这些人工智能技术与人脸识别看似不同，实则同根同源。这一些人工智能技术会让我们的生活越来越美好，未来人们会更加关注自己的生活品质而不是生存。人们的劳动会由物质生产向文化生产转变，社会人口中的绝大部门会从事第三产业--科技文化与服务产业。
<br>&#160; &#160; &#160; &#160;现在我们正在由信息化社会向智能化社会转变，语音识别技术会促进人机交互进一步发展，现在的微软小冰、度秘是基于语音识别技术设计的，语音识别技术会让人机交互变得越来越和谐和便利，未来我们人人都能拥有一个称心如意的好秘书。无人驾驶技术现在已经呼之欲出，特斯拉公司在这一领域颇有建树，特斯拉生产的自动驾驶卡车现在已经能够上路运行了；我们国内的互联网巨头百度在自动驾驶领域也一直大力发展，去年在乌镇互联网大会期间在乌镇投放了18辆无人驾驶汽车供参会者体验。人工智能问答系统在商业客服中可以大展身手，人工客服每天工作时间固定，不能加班，周末需要休息，而机器客服可以7*24小时待命，而且能够保证服务的规范和稳定。机器写作与人工写作各有所长，机器写作适合统计类、固定格式文章写作，机器写作实效性高。机器翻译现在已经相当成熟了，未来翻译是一个会走向没落的职业，机器翻译结合语音识别技术可以胜任一个熟练的同声传译工作人员的工作。人类的工作岗位会越来越多地被机器人所取代，在这个转变的过程中重复性的低端工作岗位会越来越少，失业率会上升，这将会引发严重的社会问题，政府在推进人工智能技术发展的过程程中需要晚上社会上的保障制度，加强对人民的职业引导，让更多的人走向创作的岗位。人脸识别中的最关键的技术是机器学习技术，机器学习技术中的人工神经网络因其在人脸识别中的卓越性能而极受追捧。人工神经网络是一种仿造人脑的运作模式而设计出来的一种机器学习方法，这种机器学习方法凭借着计算机的强大计算能力而取得了巨大的发展，深度学习是一种更加复杂的人工神经网络，深度学习现在被众多的科学家看好，很多人预测深度学习技术未来会创造出强人工智能。本篇中的人脸识别我先采用传统的特征脸加支持向量机技术，然后又引入了卷积神经网络。实验结果表明基于神经网络的人脸识别技术远远优于传统的基于特征的人脸识别技术。

###1.2 人脸识别的历史
<br>&#160; &#160; &#160; &#160;
人脸识别最早可以追溯到19世纪的法国科学家Galton,他证实了一个简单的神经网络可以用于人脸识别。他的神经网络在处理人脸之前会对人脸进行对齐与归一化，然后获得一个特征向量，这个特征向量现在我们称之为特征脸。
![](image/研究动态.jpg)
<br>&#160; &#160; &#160; &#160;
人脸识别技术的发展大致可以分为三个阶段：
<br>&#160; &#160; &#160; &#160;
第一阶段：基于人的几个结构提取特征，然后通过规则进行分类，这种方法非常依赖于人工，识别准确率低，现在已经无人采用；这一阶段人脸识别仅仅是作为一个单一的模式识别问题来研究。
<br>&#160; &#160; &#160; &#160;
第二阶段：这一阶段出现了人脸识别的一些代表性算法，比如FERET人脸识别算法。这一阶段也出现了一些商业运作的人脸识别项目，比如说FaceIt系统，这一阶段时间短暂但是成果丰厚。
<br>&#160; &#160; &#160; &#160;
第三阶段：通过图片预处理，克服光照、表情、姿势的的影响使得人脸识别的准确率进一步提升。这一阶段科学家们引入了新的方法，比如说支持向量机，卷积神经网络……

人们对于人脸识别的系统研究开始于二十世纪六十年代，并且在九十年代后期进入初步应用状态。

###1.3 论文结构
&#160; &#160; &#160; &#160;
本文先介绍了人脸识别系统的总体技术路线，后再分别对系统中用到的机器学习框架Scikit-learn、Keras、深度学习框架 tensorflow、网站框架Django进行介绍。介绍完技术细节后，本文还介绍了一些人脸识别中用到的经典算法，比如说主成分分析、支持向量机、卷积神经网络。

##2.技术路线

&#160; &#160; &#160; &#160;我先采用PCA＋SVM的方法进行人脸识别，PCA与SVM都是实用了Scikit-learn这个python的机器学习开源库，人脸训练数据来源于LWF，LWF是一个自然状态下标记的人脸数据库。先从从数据库中选择6个人，每个人50张照片，40张用于训练，10张用于测试；训练模型时先对人脸图片的尺寸进行缩放，然后再用PCA进行降维。然后把降维后的向量作为输入，使用SVM进行多对多分类。这种情况下人脸的识别精确度可以达到90%，但是这种方法用于我们通用的人脸识别系统是不可行的。现实的应用场景中我们对于每一个样本不可能有这么多的采样数据，我们做不到每一个人都用数十张照片进行模型训练。我尝试着把人脸模型中每个人的训练数据数目减少，但是这样模型的预测效果就特别差，几乎不能识别。

&#160; &#160; &#160; &#160;尝试过PCA＋SVM的组合后，我再采用了神经网络的识别方法，这一次我对训练模型的数据进行了更多的处理，来源数据库我也换成了Olivetti Faces,Olivetti Faces是纽约大学的一个比较小的人脸库，由40个人的400张图片构成。每个人的人脸图片数量为10张，每张图片的灰度级为8位，每个像素的灰度大小位于0-255之间，每张图片大小是64*64。神经网络我才用的是Keras CNN(卷积神经网络)，Keras是一个基于Tensorflow 与  theano 的神经网络框架，我可以在Keras中组建模型，调节参数，评估结果。Olivetti＋Keras的组合可以让人脸识别的准确率Olivetti Faces达到95%以上。对于我直接采集的人脸照片我先用openCV 中的人脸检测模型进行检测，然后再截取人脸，然后使用该截取的人脸图片进行训练与验证。

下面我来介绍一下我在整个实验过程中用过的一些技术：

###2.1 Scikit-learn与LWF
&#160; &#160; &#160; &#160;
Scikit-learn是基于Python的机器学习模块，基于BSD开源许可证；LWF(Labeled Face in the Wild)是由马萨诸塞大学(University of Massachusetts)计算机视觉实验室维护的一套公开数据库，建立的目的是为了研究非受限情形下的人脸识别问题，LWF是目前最为权威的人脸识别性能评价参照标准之一。

&#160; &#160; &#160; &#160;
先从LWF数据库中读取人脸数据与人脸标签，然后把数据分成训练数据与测试数据，训练数据用于训练模型，测试数据用于评估模型的好坏。在训练模型前需要对数据进行预处理和特征提取，在本次方案中数据预处理包括图片信息二值化，图片尺寸调整；特征提取环节采用特征脸技术，特征脸是采用PCA得到。

&#160; &#160; &#160; &#160;
在训练模型的过程中需要不断地进行参数调整，实验最初用的是少量的人脸＋大规模样本进行训练以确保模型能够准确识别出人脸，后期随着模型的逐渐优化逐渐减少训练数据中同一标签的样本的数量供给，从而训练出高鲁棒性的人脸识别模型。
###2.2 Keras卷积神经网络

&#160; &#160; &#160; &#160;
输入数据：用户从认证界面向后端传入10张标准的人脸照片(前期采用本地文件，后期增加直接拍照上传)。照片命名格式：“人名_照片序号.jpg”;照片整理程序接收前台传入的照片后创建临时文件夹img_receive,并对照片进行人脸剪裁，剪裁完后保存在img_receive文件夹中，文件夹以人的标签命名。

&#160; &#160; &#160; &#160;
训练模型:训练模型程序读取所有人脸数据库中的人脸照片，再与olivetti数据库中的人脸一起组成训练集。开始训练模型，训练完模型后保存两份，一份留作备份一份用于预测应用。

&#160; &#160; &#160; &#160;
验证程序：后台先接收一张由前台传入的人脸照片，接收的图片在调用图片处理工具程序进行剪裁与二值化后会存入制定的文件夹(img_predict)，存放前会先清空该目录。然后再调用图片转换程序把图片转化为数组(传入图片路径，传出数组)，后台会加载训练好的人脸识别模型并把该数组作为输入进行预测并返回验证结果。最后展示程序根据验证结果输出预测标签，如果没有匹配结果则返回识别失败。

详细设计：

	authtication():认证主程序;
 	rece2base:把图片由img_receive移至base/name，并调用裁剪程序;
  	getface:把人脸图像由数据库读出,返回列表,list(x,y),并调用图片转换函数;
   	train(x,y):训练模型train(x,y),训练完后保存模型;
   	auth_show():认证成功;
	verification():人脸识别(验证)主函数;
   	getPredict():返回数组x；从img_predict读取照片，调用裁剪程序，调用图片转换函数;
   	predict(x):加载模型预测数据，返回预测结果;
   	veri_show:根据模型预测结果返回人名;
	cutface(sourcePath,targetPath)：裁剪程序;
	xface(path):图片转换函数,返回数组;
##3.技术介绍
###3.1 Django
&#160; &#160; &#160; &#160;
Django是一个开放源代码的web应用框架，由Python编写而成。Django遵守BSD版权，初次发布于2005年7月，并于2008年9月发布第一个正式版1.0，Django 采用了MVC的软件设计模式。

安装：Django可以通过pip安装 pip install Django

创建Django项目：django-admin.py startproject appname

启动服务：python manage.py runserver 0.0.0.0:8000 &
 
#####3.1.1 Django url 转发
url(regex,view,kwargs,name)函数可以接受四个参数：两个必选参数：regex,view和两个可选参数：kwargs、name;

regex:正则表达式，regex匹配的URL会调用第二个参数表示的view；

view:执行regex匹配的url的请求；

kwargs：向视图传入的字典，携带数据信息；

name:用于反向获取URL。

#####3.1.2 Django 访问静态资源
settings.py 静态文件访问配置：

https://docs.djangoproject.com/en/1.8/howto/static-files/

Static files (CSS, JavaScript, Images)
 
>STATIC_URL = '/static/'
 
python manage.py collectstatic 后 STATIC_ROOT 文件夹会把所有的STATICFILES_DIRS以及各app中static文件夹中的文件复制到deploy_static目录。这样做的目的是为了更加方便地管理资源

>STATIC_ROOT = os.path.join(BASE_DIR, 'deploy_static')
>STATICFILES_DIRS = (
>    os.path.join(BASE_DIR, "common_static"),
>)

Django 默认会在 STATICFILES_DIRS中的文件夹和每个app下的static文件夹中查找文件，按顺序参照，找到后立即停止。
>STATICFILES_FINDERS = (
>    "django.contrib.staticfiles.finders.FileSystemFinder",
>    "django.contrib.staticfiles.finders.AppDirectoriesFinder"
>)

这样配置以后，才能在模版中使用后台的静态资源。
#####3.1.3 Django 获取request资源
获取参数：

    if request.POST:
        data['name'] = request.POST['test'].strip()
        
获取单个图片：

	if request.method == 'POST':
		form = PictureForm(request.POST,request.FILES)
	   if form.is_valid():
	   		image=request.FILES['imagefile']
	   		
获取图片列表：

	if request.POST:
	 	data['name'] = request.POST['test'].strip()
	  	files = request.FILES.getlist('files')

保存图片：
	
	img = Image.open(file)
		img.save(path)
	   	img_list.append(path)

######pip

	pip: Linux下的包管理工具
	
	安装:pip:https://pip.pypa.io/en/stable/installing/
	
	wget  https://bootstrap.pypa.io/get-pip.py
	
	python get-pip.py
###3.2 Scikit-learn
&#160; &#160; &#160; &#160;
Scikit-learn是基于Python的非常简单和有效的机器学习模块，基于BSD开源许可证，我们通常利用它来进行数据挖掘和分析。
   
#####3.2.1 监督学习
&#160; &#160; &#160; &#160;
监督学习是指利用已知类别的样本来训练分类器，不断调节参数，最后使分类器达到所要求的性能的过程。

有监督学习可以分成两类：

&#160; &#160; &#160; &#160;
1.回归分析(Regression Analysis)：回归分析，其数据集是给定一个函数和它的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求出一个最符合这些已知数据集的函数解析式。然后它就可以用来预估其它未知输出的数据了，你输入一个自变量它就会根据这个模型解析式输出一个因变量，这些自变量就是特征向量，因变量就是标签。 而且标签的值是建立在连续范围的。

&#160; &#160; &#160; &#160;
2.分类（Classification）：其数据集，由特征向量和它们的标签组成，当你学习了这些数据之后，给你一个只知道特征向量不知道标签的数据，让你求它的标签是哪一个？其和回归的主要区别就是输出结果是离散的还是连续的。


#####3.2.2 无监督学习

&#160; &#160; &#160; &#160;
无监督学习（unsupervised learning）就是指训练样本的标记（label）信息是未知的。无监督学习的目标就是通过对无标记样本的学习来发现数据内在的性质和规律，为进一步的数据分析提供基础。

&#160; &#160; &#160; &#160;
聚类（clustering）就是一种典型的无监督学习，聚类算法可以将无标记数据集中的样本划分为多个通常是不相交的子集。聚类算法既能作为一个单独的学习过程，用于寻找数据内在的结构，也经常用来做为其它学习任务的预处理过程。


#####3.3.3 模型选择与评估

######模型评估之交叉验证

&#160; &#160; &#160; &#160;
(1)交叉验证（Cross validation）是一种评估统计分析、机器学习算法对独立训练数据的数据集的泛化能力（generalize），能够避免过拟合问题。
交叉验证需要满足的条件：
	1）	训练集的比例要足够多，一般大于一半；
	2）	训练集与测试集要均匀抽样；
交叉验证主要分成以下几类：
	1）	Double cronss-validation
	2）	k-folder cross-validation(k折交叉验证)

&#160; &#160; &#160; &#160;k-folder cross－validation（k-CV）是Double cross-validation的延伸，做法是将数据集分成k个子集，每个子集均做一次测试集，其余的作为训练集。K-CV交叉验证重复k次,每次选则一个子集作为测试集，并将k次的平均交叉验证识别率作为结果。
3）	leave-one-out cross-validation(LOOCV留一验证法)

&#160; &#160; &#160; &#160;假设数据集中有n个样本，那么LOOCV也就是n-CV，意思是每个样本单独作为一次测试集，剩余n-1个样本则作为训练集。
(2)使用GridSearchCV进行高效调参

&#160; &#160; &#160; &#160;GridsearchCV可以根据你给定的模型自动进行交叉验证，通过调节每一个参数来跟踪评分结果，该过程可以代替进行参数搜索时的for循环过程。
(3)召回率与准确率（Precision &Recall）

&#160; &#160; &#160; &#160;准确率与召回率是广泛用于信息检索和统计学分类的两个维度值，用来评价结果的质量。其中精度是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率;召回率是指检索出的相关文档和文档库中所有的相关文档的比率，衡量的是检索系统的查全率。

&#160; &#160; &#160; &#160;一般来说，Precision就是检索出来的条目（比如：文档、网页）有多少是准确度的，Recall就是所有准确的的条目有多少被检索出来了。

&#160; &#160; &#160; &#160;正确率、召回率和F值是在各种复杂的环境中选出最佳模型的重要评价指标。
定义：
	正确率＝提取出的正确信息条数／提取出的信息条数
	召回率＝提取出的正确信息条数／样本中的信息条数
	两者取值在0和1之间，数值接近1，查准率和查全率就越高。
	F值＝正确率*召回率*2／(正确率＋召回率)
	F值是正确率和召回率的调和平均值。
#####3.3.4 计算性能


###3.3 Tensorflow

&#160; &#160; &#160; &#160;
TensorFlow 是一个开源的软件库，它采用数据流图来进行科学计算。数据流图中的节点代表数学操作，图中的边代表多维数组(张量)。灵活的架构让我们能够在桌面计算器、服务器甚至移动设备上部署计算任务，这些任务还能够尽可能地利用机器的多核资源。Tensorflow 最开始是谷歌大脑团队研发使用的，最后谷歌的工程师把它开源了，这个系统可以应用在各种领域。

&#160; &#160; &#160; &#160;
数据流图：数据流图使用节点和边来表示数学操作，节点表示数学操作也可以表示数据输入节点和输出节点。边表示可以传递尺寸可变的多维数组(张量)，各个节点之间可以异步并行地进行计算。


###3.4 KerasKeras是一个高层神经网络库，Keras基于Tensorflow或Theano。Keras为支持快速实验而生，能够把我们的想法快速转化为结果，Keras可以满足你的如下需求：

1.	Keras具有高度模块化，极简和可扩展性，所以可以用它进行简易和快速的原型设计2.	支持CNN和RNN以及两者的结合3.	支持任意链接的方案（包含多输入和多输出的训练）4.	支持无缝CPU和GPU的切换
Keras使用的Python 版本：Python 2.7-3.5
Keras设计原则：
1.	模块性：模型可以理解为一个独立的序列或图，完全可配置的模块可以以最少的代价自由组合在一起。具体来说：网络层、损失函数、优化器、初始化策略、激活函数、正则化方法都是独立的模块，我们可以用它来构建自己的模型。2.	极简主义：每一个模块都应该尽量的简洁。每一段代码都应该在初次阅读时都显得直观易懂。没有黑魔法，因为它将给迭代和创新带来麻烦。3.	易扩展性：添加新模块非常容易，只需要仿照现有的模块编写新的类或者函数就可以了。创建新的模块的简单便捷使得Keras更适合于先进的研究工作。4.	于python协作：Keras没有单独的模型配置文件类型，模型由python代码描述，使其更紧凑和更容易debug,并提供了扩展的便利性。

###3.5 OpenCV-Python
&#160; &#160; &#160; &#160;
OpenCV 是基于 BSD 协议的开源软件，可以免费地用于学术与商业用途。它拥有 C++ , C , Python 和 Java 接口，支持的平台有 Windows ，Linux , Mac OS , iOS 和 Android 。OpenCV 可以用于高性能计算和实时应用，它是用C/C++优化过的，这些库能够尽可能地发挥多核计算机的处理能力。

#####3.5.1 利用Haar-cascade进行人脸检测
&#160; &#160; &#160; &#160;
哈尔特征级联分类器是用于对象分类的有效方法。首先这个算法需要非常多的正例(人脸照片)和反例(非人脸照片)来训练分类器。我们还需要其它额外的特征，通常使用下面图片中的哈尔特征(它非常像卷积内核)，每个特征中包含了下面图片中的白色区域的像素和与黑色区域的像素和的差。

![](image/haar_features.jpg)

&#160; &#160; &#160; &#160;
所有的尺寸和位置信息都被保存在了这些哈尔特征中，我们可以用这些哈尔特征来产生出大量新的特征。哈尔特征的计算量特别大(一个24*24的图片需要计算160000个哈尔特征)，每一次计算我们都需要分别计算所有的白色矩形和黑色矩形的像素和。为了解决这个问题，我们改用积分图像，它够简化像素的求和，在整个过程中只需要计算相关的四个像素。

&#160; &#160; &#160; &#160;
这些所有的特征中绝大多数是不相关的，在下面这张图片中，上面一行给大家展示了两个有用特征，上面第一个特征跟人的两只眼睛的位置特别相关，第二个特征与人的鼻梁特别相关。这两种特征应用于面部是非常有用的，但是图片中也有很多的地方也会出现一样的特征，那时这些特征都是不相关的无用特征。我们通常使用Adaboost方法从这160000+个特征中选出一些相关特征。

![](image/haar.png)

&#160; &#160; &#160; &#160;
我们把每个个特征都做为一个分类器，通过训练数据不停地训练，最后得到一个阈值和一个分类精度。我们把160000+个这样的分类器按照分类效果排序，选择其中前6000个做为最终的特征。这样的每一个分类器都是弱分类器，它们单独的分类效果都不好，把所有的弱分类器级联起来就能够得到一个强分类器，这个强分类器的分类结果由所有的弱分类器的分类结果投票得出。这样的级连分类器效果特别好，即使只有200个弱分类器级联也能够达到95%的识别正确率。

&#160; &#160; &#160; &#160;
OpenCV 已经包含了训练好的人脸、眼睛、微笑分类器，这些 XML 文件存在 opencv/data/haarcascades/ 目录中。

	import numpy as np
	import cv2
	
	face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
	eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')
	
	img = cv2.imread('sachin.jpg')
	gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
	
	
	
	faces = face_cascade.detectMultiScale(gray, 1.3, 5)
	for (x,y,w,h) in faces:
	    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
	    roi_gray = gray[y:y+h, x:x+w]
	    roi_color = img[y:y+h, x:x+w]
	    eyes = eye_cascade.detectMultiScale(roi_gray)
	    for (ex,ey,ew,eh) in eyes:
	        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)
	
	cv2.imshow('img',img)
	cv2.waitKey(0)
	cv2.destroyAllWindows()




##4.算法介绍
###4.1 PCA算法
（1）定义：
主成分分析（PCA）是一种统计过程，它使用一个正交变换，将一组可能的相关变量的观测值转化成一组线性不相关的变量的值称为主成分（有时也称之为主要变量），主成分的数目小于或等于原变量数与观测数的较小值。将n维向量映射到k维正交向量，这一过程能够使主成分能够感知原始数据的变化。
 
###4.2 SVM

&#160; &#160; &#160; &#160;
Support vector machines(SVMs)是一系列监督学习方法的集合，我们可以用支持向量机来进行分类，回归预测和离群点检测。

支持向量机的优点：

* 在高维向量中性能突出；
* 当特征维数大于样本类别时依然有效；
* 用到了选择函数(我们称之为支持向量)的一个子集,它在内存使用方面也非常高效；
* 选择性多：可以选用不同的内核，既拥有通用的内核函数，也可以编写自己的内核函数。

支持向量机的缺点：

* 如果特征数目大于样本种数，性能会急剧下降；
* 支持向量机不直接提供估计概率，我们获得的估计概率通常是由花销极大的5折叠交叉验证法计算得来的。

&#160; &#160; &#160; &#160;
SVC 和 NuSVC 是相似的支持向量分类方法，它们的传入参数稍有不同，NuSVC 比 SVC 的参数中多了一个支持量的维数，此外在所选用的数学函数方面也有所不同。在另一方面, LinearSVC 是支持向量分类的另外一种实现方法，它所采用的内核是线性函数。LinearSVC 在构造的时候不需要接收内核函数，默认是线性函数，在属性中它比 SVC 和 NuSVC 要少一个 support_ 。

&#160; &#160; &#160; &#160;
和其它的分类器一样，SVC ， NuSVC 和 LinearSVC 的输入参数都是一个数组 X = [ n_samples , n_features ] 。
> from sklearn import svm
> X = [[0, 0], [1, 1]]

> y = [0, 1]

> clf = svm.SVC()

> clf.fit(X, y)  

>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)

>clf.predict([[2., 2.]])
array([1])

在方案一中，我的训练模型是这样的：

>param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],
              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }

>clf = GridSearchCV(SVC(kernel='rbf', 

>class_weight='balanced',probability=False), param_grid)

>clf = clf.fit(pca, np.array(aims))

>print clf.predict(np.array(myaim).reshape(1,-1))

>p=clf.decision_function(np.array(myaim).reshape(1,-1))

###4.3 卷积神经网络

&#160; &#160; &#160; &#160;
卷积神经网络（CNN）是一种前馈人工神经网络。卷积神经网络中的神经元之间的连接模式的灵感来自动物视觉皮层组织。单个皮层神经元对受限制区域的刺激反应称为感受野。不同的神经元的感受野部分重叠，使他们平铺视野。反应一个人的神经元对刺激的感受野范围内可以通过卷积运算的数学近似。卷积网络的灵感来自生物过程，它使用多层感知器进行学习感知。他们在图像和视频识别技术的广泛应用，推荐系统和自然语言处理卷积神经网络是最近发展起来的一种高效的图像识别方法，卷积神经网络用于图片识别效果特别好。Hinton于2006年发表过一篇关于自动编码的深度学习文章，但是那个时候学术界并不重视这篇论文。2009年受限玻尔兹曼机初始化神经网络成功应用于语音识别领域，大家仍然没有足够重视卷积神经网络。到了2012年，Hinton领导了他手下的团队继续在图像处理领域研究，他的两个学生使用深度学习卷积神经网络对Image Net进行识别并取得了当时世界上最好的成绩。Image Net是一个多类物体图片数据库，他们的这一举动促使了深度学习在图像处理领域前进了一大步。

&#160; &#160; &#160; &#160;
卷积神经网络的发明人并不是Hiton,Fukushima在1980年发明了神经认知机（Neocognitron）。神经认知机是世界上最早的一个具备自动学习卷积核能力的神经网络，他拥有卷积神经网络最基本的特点。1998年，Yann LeCun 研发出了手写数字识别系统,这是卷积神经网络的第一次实际应用。如今卷积神经网络中需要用到的技术：自动学习卷积核，多层结构与降采样技术在手写数字识别系统中都已经采用。

局部感知：

&#160; &#160; &#160; &#160;
下面这张图片有1000\*1000像素，100万个神经元。如果所得的神经元全连接的话就有1000\*1000\*1000000 ＝ 10^12个连接，这样的神经网络就会有10^12个权值参数。如此巨大的神经网络导致计算机难以计算，为了解决这个问题，我们让每个神经元只感知它附近的像素点，比如说只感知附近方格10\*10的像素点。如果只感知附近10\*10方格中的点，那么这些神经元的全连接数目就是10\*10\*1000000 = 10^8 ，计算量一下就减少了几个数量级。这种神经网不需要对图片的全部信息进行感知，只需要对附近的信息进行感知的思路受启发与生物视觉神经元细胞的感知机制。下面图片中左图代表全局感知，右图代表局部感知;

![](image/局部感知.jpg)

&#160; &#160; &#160; &#160;
距离神经元远的像素对神经元的影响比较小，距离神经元近的像素对神经元的影响小，局部感知把影响小的感知去除，让神经网络能够更好地把握局部信息的影响。

减少参数与共享权值：

&#160; &#160; &#160; &#160;
把全局感知改为局部感知后计算量下降了四个数量级，但是这样计算量依旧非常大，我们可以再试着减少计算量，隐含层的每一个神经元都连接着10\*10的区域，如果这1000000个神经元中所有的100个参数都是相等的，那么参数的数量就减少为100个了。我们可以用统一的采样方法进行采样，这样的采样器就好像一个筛子，对于所有的像素都才用同样的规则进行采样就能够达到减少参数和共享权值的目的。

![](image/filter.jpg)

&#160; &#160; &#160; &#160;
下面图片展示的就是用3\*3的卷积核在5\*5的的图片上做卷积，每个卷积核就是一个过滤器，它把高于阈值的特征都筛选出来了。

![](image/参数共享.gif)

多卷积核

&#160; &#160; &#160; &#160;
上面共享权值的过程中我们对于所有的像素区域都是采用同一个卷积核，这样虽然可以减少计算量，但是这样提取的特征却是不充分的，为了更加充分地提取特征，我们可以采用对个卷积核对图片信息进行多次处理，这样虽然计算量会翻倍，但是有用特征也增多了。下面的图片演示了使用多个卷积核多次采用的情形：不同颜色代表不同的卷积过程，每个卷积核都会按照自己的规则去处理图片然后提取特征生成特征图片。四个不同的卷积核就可以生成四张不同的特征图片。

![](image/多核卷积.jpg)

&#160; &#160; &#160; &#160;
下面图片中是一个拥有2层神经元节点的卷积神经网络，左边是m-1层的4个特征图，右边是m层的两个特征图。神经元在m层的输出是通过m-1层中的像素通过卷积核计算出来的。

![](image/多核卷积2.jpg)

&#160; &#160; &#160; &#160;
权值W0,W1是3维的张量，其中第一个表示特征图的索引，另外两个表示像素坐标。


最大池化

&#160; &#160; &#160; &#160;
获得图片卷积的特征后我们需要对这些特征进行分类，但是这些特征的数量太多了，一个100\*100像素的图片如果我们把局部视野定为8\*8，那么对图片进行一次卷积操作后会得到一个 (100 − 8 + 1) × (100 − 8 + 1) = 8649 维的特征向量，这样的高维特征向量是不能够直接用于模型训练与预测的。为了解决这个问题，我们可以把输入图片分割成不重叠的子区域，每个子区域只输出最大值，这种方法我们称之为最大池化(max-pooling)，最大池化可以降低特征向量的维度，对于位移变化具有良好的鲁棒性。

![](image/Down-pooling.gif)

多层卷积网络

&#160; &#160; &#160; &#160;
多层卷积网络是把单层卷积神经网络一层一层地连接起来，然后再使用全连接层进行训练，多层卷积网络能够克服单层卷积局部化，随着层数增加，多层卷积网络学到的特征越全局化。

参数选择

1.卷积层滤波器数量

&#160; &#160; &#160; &#160;
特征图的大小会随着层数的增加而变小，为了让每一层的计算量保持一致，特征图的大小乘以特征图的数量在每一层应该保持在一个常量附近。通常特征图的数量会随着层数的增大而增加。

2.滤波器形状

&#160; &#160; &#160; &#160;
滤波器的形状应该根据图片的大小确定，我们应该根据数据的实际情况选择相同粒度大小的滤波器形状。

3.最大池化形状

&#160; &#160; &#160; &#160;
池化在降维的同时会导致信息损失，通常取2\*2或者不用最大池化，大一点的图像可以在低层使用4\*4。


AlexNet

&#160; &#160; &#160; &#160;
ImageNet 含有120万张彩色图片，这些图片一共有1000个类别，ImageNet 是当今世界上规模最大的图像识别数据库。Alex 构建了一个超过65万神经元的卷积神经网络，该神经网络所包含的权值参数超过6亿,这个网络就是AlexNet。

![](image/ImageNet-2010网络结构.jpg)

上图模型的基本参数为：

	输入：224×224大小的图片，每个像素有红绿蓝(RGB)3通道,输入维数为：224\*224\*3 = 150528。 
	
	第一层卷积：96个11×11卷积核；
	
	第一层池化：2×2卷积核；
	
	第二层卷积：256个5×5卷积核；
	
	第二层池化：2×2卷积核。
	
	第三层卷积：384个3*3卷积核；
	
	第四层卷积：384个3×3卷积核；
	
	第五层卷积：256个3×3卷积核；
	
	第五层池化：2×2的核；
	
	第六层全连接：这一层将上一层所有的输出连接成一个4096维向量；
	
	第七层全连接：把上一层的输出作为输入；
	
	Softmax层：输出1000个类中的一个。

&#160; &#160; &#160; &#160;
Alex Krizhevsky等人在ImageNet的测试集上获得了37.5%的错误率，这个结果遥遥领先于其他选手。

深度神经网络在人脸识别上的应用

&#160; &#160; &#160; &#160;
香港中文大学的教授汤晓欧、王晓岗带领的团队研发了一个基于深度学习的DeepID网络，这个网络在LFW（Labeled Faces in the Wild）数据库上获得了99.15% 的识别率，人的肉眼识别率是97.52%，DeepID 已经领先于人眼，下图是DeepID的网络结构。

![](image/DeepID网络结构.jpg)

&#160; &#160; &#160; &#160;
DeepID技术先根据人脸关键点做人脸对齐，然后根据关键点对人脸的不同部位进行裁剪，通过这种手段把人脸分解成30张图片，再把图片转化为灰度图，一共是得到60张图片。分别对这些图片构建神经网络，把正方形图片转化为31\*31像素的输入，矩形图片转化为39\*31像素作为输入，最后该神经网络的输出是一个160维的向量。


##5.实验数据
###5.1 Scikit-learn实验数据
Total dataset size:
n_samples: 1288
n_features: 1850
n_classes: 7
Extracting the top 150 eigenfaces from 966 faces
done in 0.377s
Projecting the input data on the eigenfaces orthonormal basis
done in 0.032s
Fitting the classifier to the training set
done in 22.852s

从LWF中选取图片数目最多的7个人：

人名       			|图片数目
--------------------|------
Ariel_Sharon			|77
Colin_Powell			|236
Donald_Rumsfeld		|121
George_W_Bush			|530
Gerhard_Schroeder	|109
Hugo_Chavez 			|71
Tony_Blair 			|144

实验获得的准确率与

![](image/scikit-learn.jpg)

###5.2 Keras实验数据
##6.平台展示
###认证、验证平台界面
##7.程序测试
###程序测试
##8.结论

##9.致谢

##10.参考文献
［1］ArchanaVijayan* ,Shyma Kareem ,Dr.Jubilant J Kizhakkethottam.Face recognition across gender transformation using SVM Classifier[J].ArchanaVijayan et al. / Procedia Technology 24 (2016) 1366 – 1373
［2］魏华珍,何松华,卢坤.融合局部贝叶斯分类器的人脸验证[J]第 43 卷第 3 期 光电工程Opto-Electronic Engineering P80-87［3］梁路宏 艾海舟 何克忠.基于多模板匹配的单人脸检测[J]中国图象图形学报 825-828［4］张洪明 赵德斌 高 文.基于肤色模型、 神经网络和 人脸结构模型的平面旋转人脸检测[J]计算机学报第二十五卷11期 1250-1256［5］张文超1+, 山世光2, 张洪明1, 陈 杰1, 陈熙霖2, 高 文1,2。基于局部 Gabor 变化直方图序列的人脸描述与识别*［J］Journal of Software, Vol.17, No.12, December 2006, pp.2508-2517
［6］梁路宏 艾海舟 徐光  张 钹.人脸检测研究综述[J]计算机学报［7］张翠平 苏光大。人脸识别技术综述［J］中国图象图形学报P885-894
［8］Amrit Kumar Agrawala, YogendraNarainSingh.Evaluation of Face Recognition Methods in Unconstrained [J]646 Environments


参考资源
[1] http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B 栀子花对Stanford深度学习研究团队的深度学习教程的翻译
[2] http://blog.csdn.net/zouxy09/article/details/14222605 csdn博主zouxy09深度学习教程系列
[3] http://deeplearning.net/tutorial/ theano实现deep learning
[4] Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.
[5] Sun Y, Wang X, Tang X. Deep learning face representation from predicting 10,000 classes[C]//Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. IEEE, 2014: 1891-1898.


